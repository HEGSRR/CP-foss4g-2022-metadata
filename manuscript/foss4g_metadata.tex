% Version 2020-12-15
% update – 161114 by Ken Arroyo Ohori: made spacing closer to Word template throughout, put proper quotes everywhere, removed spacing that could cause labels to be wrong, added non-breaking and inter-sentence spacing where applicable, removed explicit newlines
% update – 010819 by Dennis Wittich: made spacing and font size closer to Word template, updated references and references style
% update – 042319 by Dennis Wittich: font size of captions set to 'small', first author names are shortened, hyphenation fixed
% update – 010620 by Dennis Wittich: Footnotes alignment set to left
% update - 151220 by Clement Mallet: Template adapted for double blind full paper submissions
% update - 060321 by Christian Heipke: Template refined for double blind full paper submissions
% update - 090921 by Christian Heipke: Template refined for double blind full paper submissions

\documentclass{isprs} % isprs class modified 23-04-2019 (Dennis Wittich)
\usepackage{subfigure}
\usepackage{setspace}
\usepackage{geometry} % added 27-02-2014 Markus Englich
\usepackage{epstopdf}
\usepackage[labelsep=period]{caption}  % added 14-04-2016 Markus Englich - Recommendation by Sebastian Brocks
\usepackage[british]{babel} 
\usepackage[hang]{footmisc}
\usepackage[authoryear,round,longnamesfirst]{natbib}
\renewcommand{\bibsection}{\section*{References}}
%\bibliographystyle{isprs}
\def\footnotemargin{1em} % added 08-01-2020 Dennis Wittich





%\usepackage[authoryear]{natbib}
%\def\bibhang{0pt}

\geometry{a4paper, top=25mm, left=20mm, right=20mm, bottom=25mm, headsep=10mm, footskip=12mm} % added 27-02-2014 Markus Englich
%\usepackage{enumitem}

%\usepackage{isprs}
%\usepackage[perpage,para,symbol*]{footmisc}

%\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\captionsetup{justification=centering,font=normal} % thanks to Niclas Borlin 05-05-2016
\captionsetup[figure]{font=small} % added 23-04-2019 Dennis Wittich
\captionsetup[table]{font=small} % added 23-04-2019 Dennis Wittich

\begin{document}

\title{Mainstreaming metadata into research workflows to advance reproducibility and open geographic information science}
\date{}


% KAO: Remove extra spacing
% Anonymous submissions, authors' names should not be visible
\author{J. Holler\textsuperscript{1,}\thanks{Corresponding author}\ \ and P. Kedron\textsuperscript{2}}

% KAO: Remove extra newline
% Anonymous submissions, authors' affiliations should not be visible
\address{\textsuperscript{1}Department of Geography, Middlebury College - josephh@middlebury.edu \\
\textsuperscript{2}School of Geographical Sciences and Urban Planning, Arizona State University - peter.kedron@asu.edu}


% If the corresponding author is NOT the final author, always add a % space before the subsequent comma, i.e.
% first author name\textsuperscript{a,}\thanks{Corresponding author} , % second author name \textsuperscript{b}, etc.
% thanks to Niclas Borlin 05-05-2016


\commission{IV, }{} %This field is optional. If filled, XX and YY should be replaced by adequate numbers. See https://www2.isprs.org/commissions/
\workinggroup{IV/4} %This field is optional.
\icwg{}   %This field is optional.

% KAO: Use times symbol
\abstract{Reproducible open science with FAIR data sharing principles requires research to be disseminated with open data and standardised metadata.
Researchers in the geographic sciences may benefit from authoring and maintaining metadata from the earliest phases of the research life cycle, rather than waiting until the data dissemination phase.
Fully open and reproducible research should be conducted within a version-controlled executable research compendium with registered pre-analysis plans, and may also involve research proposals, data management plans, and protocols for research with human subjects.
We review metadata standards and research documentation needs through each phase of the research process to distil a list of features for software to support a metadata-rich open research life cycle. 
The review is based on open science and reproducibility literature and on our own work developing a template research compendium for conducting reproduction and replication studies.
We then review available open source geographic metadata software against these requirements, finding each software program to offer a partial solution.
We conclude with a vision for software-supported metadata-rich open research practices intended to reduce redundancies in open research work while expanding transparency and reproducibility in geographic research.}

\keywords{Metadata, Open Science, Reproducibility, Open Source GIS}

\maketitle

%\saythanks % added 28-02-2014 Markus Englich

% KAO: Sloppy spacing ensures non-overfull lines. Can be removed if this is not an issue.
\sloppy

\section{Introduction}\label{Introduction}

Can the scientific community expand knowledge production and the scope of inquiry, accelerate and improve scientific communication, and improve scientific rigour?
These are the motivations of open science principles---to expand the availability and usability of scientific research publications, data, and methods \citep{NASEM2018}, thereby making scientific studies more reproducible  and enabling new forms of inquiry based on synthesis and meta-analysis \citep{NASEM2018,NASEM2019}.
However, one key barrier to reproducible open science is a lack of standardised metadata documentation for research projects and associated data, code, and processing environments (Ibid.).
The National Academies of Sciences, Engineering and Medicine \citep{NASEM2018} \textit{Open Science by Design} report therefore calls for adherence to the FAIR principles \citep{Wilkinson2016} for sharing research data in a findable, accessible, interoperable, and reusable manner.
According to the report, achieving FAIR principles for open science will require infrastructure---data repositories and metadata annotation software---and additional researcher labour to document metadata in the preservation phase of the research life cycle \citep{NASEM2018}. 
\citet{Leipzig2021} suggest that metadata may even help resolve the reproducibility crisis in computational research.
Therefore, we argue that the crucial task of documenting and sharing data about data must be a continuous part of the research process.

We propose that researchers formally utilise and create metadata from the inception of a research project and maintain metadata throughout the full research life cycle.
Open source geographic information systems software should support metadata-rich research life cycles from inception through dissemination and preservation.
These changes in research practices and infrastructure should increase the reproducibility of geographic research and indirectly increase the pace and credibility of knowledge production. 

Our proposal is based on a growing reproducibility literature in the social and geographical sciences and on our experience conducting reproductions and replications of geographic research and training geography students in reproducible research practices \citep{Kedron_Holler_Bardin_Hilgendorf_2022}.
In particular, we have developed templates for pre-analysis plan registrations, reproduction and replication study reports, and reproducible research compendiums \citep{Kedron_Holler_2022}, and we have applied the templates to seven reproduction and replication studies conducted with teams of students and research assistants \citep{Kedron_Holler_Bardin_Hilgendorf_2022}.
We suggest that rather than redundantly writing about their data through all phases of a research work cycle, researchers could formalise metadata at the project inception, use the metadata for much of the required documentation, and use software to maintain and track changes in metadata throughout the research process.
Furthermore, we anticipate that a metadata-rich research life cycle would enhance the quality and transparency of metadata in open science by more thoroughly and consistently recording information about data provenance, license, access, and distribution.
High quality metadata is also the next best solution for reproducibility in cases of restricted proprietary or confidential research data.

In the following section, we review the most important metadata standards for documenting geographic research and discuss the role of metadata in each phase of an open science research life cycle.
We then describe our methods for selecting and reviewing open source software tools for annotating and maintaining metadata in support of metadata-rich research life cycles.
We discuss the existing capabilities of open source software and conclude with suggested directions for future development in support of reproducible open science.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Geographic Metadata for Reproducible Open Science}\label{sec:Background}

Open science aims to enhance the transparency, accessibility, and reproducibility of scientific research \citep{NASEM2018}.
In geographic information science, this can be achieved with open public domain data, open source GIS software, public research workflows, and peer review inclusive of data and workflows \citep{Singleton2016}. 
Following the National Academies of Science, Engineering and Medicine \citep{NASEM2019}, a reproduction study aims to find the same results using the same data and methodology as a published study.
Once a study is reproducible, it becomes possible to reanalyse the original study design by purposefully altering parameters or procedures using the same data \citep{Christensen2019}. 
Reanalysis studies provide insight into the sensitivity of original results by testing the internal validity of the finding and  demonstrating how the finding compares to a set of findings produced by possible alternative analyses. 
A replication study aims to test the findings of a published study by collecting new data and following a similar methodology \citep{NASEM2019}.
Whereas a study may be reproducible if original data is provided, replication will require complete metadata in order to create new data following the same procedures \citep{Ostermann2017}.
Preliminary assessments of replicability and reproducibility in the geographic sciences have excluded many studies because of missing research components \citep{Ostermann2017,Konkol2019}.
From the remaining sample of publications, the majority of volunteered geographic information publications were not reproducible \citep{Ostermann2017} and the majority of spatial-temporal figures were not identically reproduced by provided code \citep{Konkol2019}.

Together, reproduction, reanalysis, and replication studies can offer a deep understanding of the original research, test its credibility, and enhance the self-corrective mechanisms of the scientific community \citep{Christensen2019,NASEM2019}.
Over a series of replication studies, alternative hypotheses can be tested across geographic contexts to develop generalizable theories through the accumulation of evidence \citep{Kedron2022}.
However, the classic geographic research challenges of spatial heterogeneity, spatial dependence, and scale dependence imply that geographers will require distinctly geographic approaches and standards to achieve reproducibility \citep{Kedron2021,Brunsdon2020} and evaluate evidence from replications \citep{Kedron2022}.
The process of reproducing existing work starts with using metadata about the research process to understand what was done, so that the research can be repeated. 
High quality metadata is also required to moving to the more complex processes of reanalysing published work, replicating it in a new context, or critically assessing a set of published studies, because metadata contains information crucial to understanding the logic used to shape the original research claim(s).

Open and reproducible science requires data to be findable, accessible, interoperable, and reusable (FAIR), and each of the four FAIR guiding principles require metadata \citep{Wilkinson2016, NASEM2018}.
Metadata is information that describes data, providing essential context about the data so that other users can find, access, and use the data appropriately.
\citet{Kim1999} summarises seven essential categories of geographic metadata based on common standards: identification (title, keywords, authors), data quality, spatial data organisation (e.g. raster or vector model), spatial reference (coordinate system and datum), entity and attributes (data dictionary), distribution (contact, licenses, and fees), and metadata authorship

\citet{Schuurman2006} and \citet{Comber2008} argue that metadata lack sufficient social and ontological context to evaluate data usability and facilitate semantic interoperability.
Researchers need more information on data quality, sampling method, attribute name definitions, measurement specifications, classification systems, data models, collection rationales, and policy and legal context \citep{Schuurman2006}.
This may require ontological and perhaps even ethnographic study of the social context in which data was created \citep{Schuurman2008}.
In the context of metadata for open science and reproducibility, the most recent international standards for data (see section \ref{sec:Metadata}) have answered many of these critiques with metadata classes for measurement, lineage, data quality, and usage.
For additional social, semantic, and ontological information, bundling or linking data with publications and executable research compendiums should add substantial additional context for data reuse.

The important lesson here is that the data, metadata, and publication should be bundled and linked together in the form of a compendium with persistent identifiers.
However, according to \citet[137-8]{NASEM2018}, ``Making data `interoperable' and 'reusable' can only be achieved if the data are annotated with comprehensive, standardised, high-quality metadata... [T]he absence of necessary metadata standards, appropriate ontologies, and easy-to-use annotation tools is a significant barrier.''
Although geography does have metadata standards (see section \ref{sec:Metadata}), the open source geospatial software ecosystem may need improved tools for mainstreaming geographic metadata into the full research life cycle (section \ref{sec:lifecycle}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Metadata Standards for Geographic Research}\label{sec:Metadata}

In the previous section, we reviewed the critical importance of geographic metadata for open science and reproducibility.
Despite this importance, scientific disciplines tend to lack sufficient standards for data sharing, interoperability, and documentation \citep{NASEM2019}.
Fortunately, the geospatial industry has standard formats, protocols, and algorithms for storing, distributing, and analysing geographic data---all coordinated by the Open Geospatial Consortium (OGC: www.ogc.org).
However, the OGC has left metadata standards to the spatial data infrastructures (SDIs) of individual states and regions, including the Federal Geographic Data Committee's (FGDC) Content Standard for Digital geographic metadata (CSDGM) in the United States, and the Infrastructure for Spatial Information in Europe (INSPIRE) \citep{Kim1999,Bartha2011}.
Individual SDIs are increasingly following and harmonising with the International Standards Organization (ISO) series of geographic information metadata standards, especially the 19115 standard \citep{ISO2014} for geographic information metadata and the 19139 standard \citep{ISO2019} for encoding metadata in extensible markup language (XML).
While the ISO standards are copyrighted and costly to purchase, researchers may access them through the many SDIs and open source geospatial software projects that have implemented them.

At the project level, research publications and compendiums can be documented with the Dublin Core\texttrademark{}  standard metadata elements \citep{DCMI2005}. Elements of the ISO 19115 and Dublin Core standards that are relevant for open science and reproducibility are summarised in Table \ref{tab:Metadata_Standards}, with similar concepts arranged on the same row. We have omitted information about language, character sets, and maintenance/accrual common to both standards.

\begin{table}[h]
	\centering
		\begin{tabular}{|c c|}\hline
		    ISO 19115 &                     Dublin Core\\\hline
			Dataset name &                  Title  \\
			Abstract &                      Description \\
			Purpose &                       Audience \\
			Keywords &                      Subject Keywords \\
			Topic Category &                -- \\
			Unique Identifier &             Identifier \\
			Date &                          Date \\
			Contact / Responsible parties&  Author \\
			Credit &                        Contributors \\ 
			Citation &                      Creator, Publisher \\
			Spatial resolution &            -- \\
			Extent (spatial \& temporal) &  Coverage \\
			Spatial representation &        Type \\
			Temporal resolution &           -- \\
			Content information &           -- \\
			Constraints &                   Rights \\ 
			Data quality &                  -- \\
			Lineage &                       Provenance \\
			Usage &                         -- \\
			Distribution and format &       Type \\
			Metadata about the data &       -- \\
			\hline
		\end{tabular}
	\caption{Summary of geographic metadata standards.}
\label{tab:Metadata_Standards}
\end{table}

The ISO 19115 standards are specifically designed for geographic data types, whereas the Dublin Core is a simpler general standard suitable for archived objects and collections.
In the ISO standard, lineage information is capable of including multiple source datasets and sequences of processing steps referencing specific software algorithms, whereas the Dublin Core lineage is more like a chain of custody of owners or stewards.
The ISO spatial representation types are highly specialised, including raster, vector, topological, and three dimensional formats, whereas Dublin Core offers a single field for resource type. 
ISO content information may include metadata and descriptive statistics specific to raster data, remote sensing imagery, or vector features, attributes and attribute statistics. 
Citation information can include bibliographic information and persistent identifiers like the digital object identifier (DOI). 
Constraints may include many types, including copyright, patent, license, privacy, statutory, confidentiality, and more. 
Distribution metadata provides space for specific instructions on how to access the original data, including the format in which the data is provided.

In sum, the Dublin Core standards for the overall research project and the ISO 19115 standards for geographic data layers provide a structured foundation to support reproducibility and open science throughout the research life cycle.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Open Science Research Life Cycle}\label{sec:lifecycle}

The 2018 \citeauthor{NASEM2018} report \textit{Open Science by Design} envisions open science practices in all six phases of the research life cycle: provocation, ideation, knowledge generation, validation, dissemination, and preservation. 
However, the report singles out the preservation phase for metadata documentation.
In the subsections below, we outline each of the life cycle phases and argue that metadata creation in each plays a key role in achieving the aims of open science.

\subsubsection{Provocation}

In the provocation phase, researchers review literature and data to identify opportunities for novel contributions.
As they gather and review prior studies and arguments, researchers would clearly benefit from a metadata-rich open science environment.
Easily accessible and rich metadata reduce the time and effort needed to critically assess the logic and argumentation of existing studies.
More formally, with open geographic data and metadata for published literature, researchers could design geographically-explicit bibliometric analyses and synthesis studies.
For example, quantitative meta-analyses seeking to estimate effect sizes from studies conducted in different geographic contexts could use geographic metadata to introduce simple controls for effect variation across regions or the sensitivity of effect estimates to the scale of original research. 
This type of regional or scalar differentiation or adjustment is not currently possible in human-environment geography because the geographic metadata does not exist.
\citet{Margulies2016} review 437 global change science case studies and find persistently ambiguous descriptions of geographic extents. 
Researchers would also gain more detailed insight into the data and methodology of the studies they review with human-readable forms of metadata for each component of the study, helping to clarify the ambiguity of communicating complex computational methods with narrative publications.

\subsubsection{Ideation}

In the ideation phase, researchers investigate data; and then plan, prototype, and preregister research designs.
Three different types of plans are required of ethical and open research in this phase: 1) protocols for research with human subjects for ethical review \citep{DHEW1978}, 2) research proposals and their associated data management plans (DMPs)\citep{NSF2021}, and 3) pre-registered analysis plans \citep{Nosek2018}. 
The primary purpose of reporting research with human subjects is to protect the privacy and rights of research subjects \citep{DHEW1978}. 
The purpose of DMPs is to explain data management protocols \citep{NSF2021} but also increasingly to explain how data will be made available to the public according to open science principles \citep{Gil2016}. 
The purpose of pre-registering analysis plans is to enhance the transparency and replicability of scientific studies, encouraging researchers to objectively carry through with deductive research plans and report results \citep{Nosek2018}. 
The idea is to avoid unobserved selective inference (e.g., p-hacking), remove false positives from the literature, and increase (or perhaps recover) reliability and inferential power.

These plans are essentially narrative metadata---documentation about the research process and could be supported by project-level and data-level metadata. 
Each of the three types of plans require project-level identifying metadata: title, authors, personnel and contributors, abstract or summary, location or spatial extent, and temporal extent. 

The plans also require metadata about each data layer. 
If secondary data is to be used, researchers are required to investigate their metadata and report on any use restrictions. 
If primary human subjects data is to be collected, researchers must specify the sampling methodology. 
Ethics review additionally requires specification of the recruitment protocol and survey instrument. 
Data collection methods and data variables should be described for all human and environmental data. 
Each of the plans also requires researchers to specify protocols for storing, archiving, and disseminating research data. 

Plans diverge in some data-specific reporting requirements. 
The pre-analysis plan requires additional detail on planned data transformation and analysis methods---essentially looking forward to documenting provenance and lineage. 
Pre-analsyis registration is ideally accomplished without viewing data directly, and therefore relies heavily on fully specified metadata for any secondary sources \citep{Nosek2018}. 
The human subjects review requires additional focus on treatment of personally identifiable information, confidentiality, and data security \citep{DHEW1978}. 

In sum, the ideation phase requires researchers to study metadata for any secondary data sources they plan to use, and to specify metadata for any data they plan to create.
In the current state of practice, this metadata documentation is required in narrative form in a variety of documents.
We propose that formalising metadata documentation in this research phase could mitigate redundancies by first populating metadata with required information, and then reusing that information for each of the planning documents required in this phase.
This change in research practice would also increase transparency if the metadata is stored in a research compendium using Git version tracking, so that any changes to intended data creation or dissemination protocols can be visualised across versions of the project.  

\subsubsection{Knowledge Generation}

In the knowledge generation phase, researchers use open source software tools to collect and analyse data in interoperable formats with sufficient documentation, metadata, and computational notebooks to enable future reuse and replication.

Ideally, researchers will organise their materials and methods for computational research in a structured executable research compendium \citep{Singleton2016,Nust2021} containing all of the narrative, data, code, software, and computer scripts required to compile the final publication starting with raw data.
Computational notebooks like Jupyter notebooks or R Markdown are commonly used to interweave narrative with code in executable compendiums (ibid).
It is recommended to store compendiums in version tracking systems like Git in order to preserve a full history of changes to the research project \citep{Stodden2014}, and to integrate compendiums into the full research workflow from knowledge generation to publishing \citep{Kray2019}.
Compendiums should implement a routine structure for research components, including directories for procedures or code, documents, raw data, processed data, and results \citep{Kedron_Holler_2022,Christensen2019,Marwick2018}.
In addition to this structure, the compendium components should be well-documented with metadata \citep{Kedron_Holler_2022,Marwick2018}.

During the knowledge generation phase, metadata records should be maintained and updated with complete provenance information on the origins of the data and a history of all data transformations \citep{NASEM2019,Tullis2021}.
Provenance is essential for reproducibility \citep{Kedron2021} and understanding the quality of data within the research and the quality and context of the research data if its to be reused elsewhere \citep{Tullis2021,Schuurman2006}.
The complexity of computational research in geography implies that provenance metadata is a necessary precursor for communication and reproduction of research methodologies, and therefore software to automate provenance records may improve reproducibility \citep{Kedron2021}.
Adhering to this logic, \citet{Anselin2014} created a metadata system for spatial weights matrices in  a form that both records human-readable provenance and machine-readable instructions for reproducing the analysis.
As such complex computational research methods diverge from the original pre-registered plan, Git can track and visualise changes to metadata updated during the knowledge generation phase, lending transparency to intended changes and unintended deviations.

\subsubsection{Validation}

In the validation phase, researchers analyse, visualise, interpret, and validate results while sharing preliminary findings in working papers and conferences.
Surveys of publications presented in the AGILE \citep{Nust2018} and GIScience \citep{Ostermann2021}  conferences found the majority of papers irreproducible due to missing metadata, data, and procedures.
At this phase, the overall project and any public project component can be registered and assigned a persistent link like the DOI through digital repositories like Open Science Framework (OSF) or figshare.
Registration requires project-level metadata to enable archiving and searching.
Although researchers may be reluctant or constrained to release complete data at this phase, metadata can be shared for project components that must remain private or embargoed.

\subsubsection{Dissemination and Preservation}

In the dissemination phase, the research is peer reviewed, revised, and published, ideally with associated data and code.
A version of the research compendium should be made available for the peer review process \citep{Singleton2016}, complete with research data, procedures, and metadata.
Some scholars are calling for reproducibility to become a standard criteria for author guidelines and peer review, with the ideal paper supported by metadata records of data and provenance \citep{Gil2016,Nust2018}.
In response to reviews, any changes to the research procedures can ideally be documented and tracked through changes in metadata and release of a final version of the compendium.

Finally, in the preservation phase, the manuscripts, data, and code are placed in FAIR digital archives with final revisions of metadata.
In other words, an open access research compendium should be published and archived with metadata specifying access, licenses, data quality, and limitations. 
\citet{Wilson2021} propose a five-star system for rating the reproducibility of such compendiums.
Publishing data and code with some metadata is only two-star level reproducibility: complete implementation of international metadata and encoding standards earns four stars.
For example, researchers could earn four stars by storing data with Open Geospatial Consortium (OGC) standard formats, document metadata with ISO standards, and encode the metadata in XML.
Documenting and containerising the processing environment would earn the fifth star.

Due to the proprietary, private, or voluminous nature of some data, it may not be possible to release a fully reproducible research compendium.
Researchers may need to alter or fabricate alternative data for the purposes of reproducibility, e.g. through simulation, jittering, or sampling \citep{Tullis2021,Singleton2016}. 
In this case, metadata is essential for documentation of original data, means for accessing original data, and methods for creating alternative demonstration data.

In order to maximise the findability and legibility of the research compendium for both humans and machines, the overall repository and each of its components must be meticulously documented with metadata according to international standards \citep{Wilkinson2016,Wilson2021}.
For instance, GitHub repositories have readme and citation files to facilitate this, while OSF projects have project-level metadata and the ability to register DOI persistent identifiers.

In our own template compendium \citep{Kedron_Holler_2022}, we have used a project-level readme document with links to comma-separated values tables to orient researchers and readers to the compendium contents, including data layers, procedural code, and results.
We designate a metadata directory for storage of more complete information about each data layer, where XML files using international standards can be placed.
We have found this compendium design to be sufficient, but maintaining complete and accurate metadata has been tedious.
We are therefore looking for open source software options to improve our metadata management in the reproducible research compendium.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Materials and Methods}\label{methods}

In this section, we describe our approach for reviewing metadata capabilities of open source geographic information software.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Open source geographic information systems}\label{software}

Following \citet{Singleton2016}, we focused on open source software for the purposes of open science and reproducibility.
We identified software to evaluate by searching for candidates on the FGDC's ISO geographic metadata Editors registry (https://www.fgdc.gov/metadata/iso-metadata-editor-review-v2), the OSGEO Projects (https://www.osgeo.org/projects/), packages compatible with spatial data science in R or Python, and literature on reproducibility in geography.
We have excluded proprietary software and software that has not been recently updated or maintained. 
For example, CatMDEdit was last updated in 2014 (version 5.0) and is not longer maintained. 

Our metadata software search ultimately discovered several different types of applications.
Desktop GIS like QGIS \citep{QGIS2022}, GRASS \citep{grass2020}, and SAGA \citep{gmd-8-1991-2015} are designed for interactive data visualization, editing, and processing.
The R and Python programming languages are increasingly used for geospatial analysis, prompting development of specialised packages for managing geographic metadata in those languages. 
Examples include the geometa package \citep{blondel_2022} for R and the pygeometa package \citep{pygeometa} for Python.
Catalogue services like GeoNetwork \citep{geonetwork} are designed for maintaining and sharing databases of searchable geographic metadata.
Content Management Systems (CMS) like GeoNode \citep{geonode} are designed to store and share geographic data in searchable web-accessible archives.
Specialised metadata authoring software like MetadataWizard \citep{usgs} and mdEditor \citep{ADIwg} allow users to author and maintain geographic metadata in a stand-alone application.
Finally, o2r-meta \citep{nust_daniel_2021_5106499} is python software designed to support metadata in the o2r executable research compendium.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{What do we need from metadata software?}\label{metadataneeds}

Based upon our review in section \ref{sec:Background} above, we have enumerated useful characteristics for open-source software in support of open and reproducible research (see table \ref{tab:Metadata_Software} columns).
The specific characteristics fall into three main categories: (1) ease of use and start-up, (2) implementation of metadata standards, and (3) automated features to facilitate metadata management.

\begin{table*}[ht!]
    \centering
    \begin{tabular}{p{1.3cm}p{1.3cm}p{1.1cm}p{1.3cm}p{1.3cm}p{1.3cm}p{1.3cm}p{1.3cm}p{1.2cm}p{1.3cm}}
    \hline
         Software     & Start-up & GUI  & Standards & Encoding & Cataloguing & Automated   & Automated & Validate  & Provenance  \\
                                &          &  Editor &        &        &     & Geographic  & Attribute &           &               \\ [1mm]
        \hline
        mdEditor                & very easy & yes & ISO, FGDC & JSON                & no            & no    & no    & yes & no  \\ [0.5cm]
        Metadata Wizard 2.0.7   & very easy & yes & FGDC    & XML                  & no            & yes   & yes   & yes & no  \\ [0.5cm]
        QGIS 3.24.3             & easy      & yes & none         & XML             & browser       & yes   & fields view & yes & no  \\ [0.5cm]
        SAGA 7.8.2              & easy      & no & none          & none            & rasters only  & yes   & yes & no & yes  \\ [0.5cm]
        GRASS 7.8.5             & easy-hard & addon & addons for ISO  & XML          & no            & yes   & no    & no & no \\ [0.5cm]
        Geometa 0.6-6           & hard      & no & ISO  & XML                     & no            & no    & no & yes & no  \\ [0.5cm]
        pygeometa 0.11.0        & hard      & no & ISO  & XML, YAML                     & no            & no    & no & --- & no  \\ [0.5cm]
        o2r-meta                & hard      & no & none & XML, JSON                     & yes           & yes   & no & yes & no  \\ [0.5cm]
        GeoNetwork 4.2.0        & hard      & yes & Dublin, ISO & XML         & no            & no    & no & yes & no \\ [0.5cm]
        GeoNode 3.3.2           & very hard & yes & Dublin, ISO, FGDC & XML    & no            & yes   & yes & no & no  \\ 
        \hline
    \end{tabular}
\caption{Spatial metadata software capabilities.}
\label{tab:Metadata_Software}
\end{table*}

First, metadata software should be easy to set up and to use in order to ease the burden of metadata documentation and management on precious research resources.
Software support for metadata management varies tremendously with regard to set-up and installation.
Stand-alone desktop metadata editors tend to be very easy to install and start using straight away, while internet-based metadata editing services require only a web browser and login.
Desktop GIS software is similarly straightforward to install and run, but some systems have additional difficulties in setting up databases or installing required plugins or add-ons.
Packages for computer languages require advanced knowledge of metadata and programming in order to install and learn their functions.
Finally, content management systems (CMS) require installation, server administration, and user login prior to working with any metadata. 

Graphical user interfaces (GUIs) enhance ease of use and learning how to document metadata, especially for novice users.
Interactive features can aid users with features like help documentation about each metadata field, auto-populated lists of keywords from standard dictionaries, selection of spatial and temporal extents, highlighting incomplete required fields, and organising complex information into separate sections or tabs.

Second, geographic metadata in an open science framework should be documented with common international standards. 
Dublin Core is the present standard for documenting the overall research project. 
ISO 19115 is the present international standard for documenting individual data layers.
The United States FGDC CSDGM standard for data layers is similar to ISO 19115, and the federal government is in the process of adopting ISO 19115.
The European INSPIRE standard for data layers is an extension to ISO 19115. 
If metadata software does not support these common standards, then the metadata may prove useful internally to the research team, but it will not easily be integrated with archives or CMSs or included in automated synthesis or meta-analysis research.

Once metadata conforms to international standards, it should also be encoded and stored with open machine- and human-readable standard formats. 
The use of an open standard and open machine-readable format enables interoperability with CMSs and automated synthesis research algorithms.
If metadata is readable by computers with common parsers, then the metadata can be integrated with more general research management tools to perform functions like creating and updating pre-analysis plans, data management plans, human subjects research protocols, or research compendium documentation.
In addition, Git can track versions of text-based formats like Extensible Markup Language (XML), JavaScript Object Notation (JSON), and YAML Ain't Markup Language (YAML).
This implies that as metadata changes over time, Git can be used to visualise differences in metadata over different phases of a research project, from pre-registration of the analysis plan to reporting results and finalising the peer review process.
Git's difference visualisation could highlight changes in spatial extent, the data dictionary of variables to be collected or computed, protocols for access, and more---even for restricted datasets.

Third, metadata software can automate the discovery, creation, and verification of metadata.
In terms of discovery, software can catalogue data layers and partially automate documentation of geographic and attribute metadata.
Many desktop GIS and geographic data catalogues can automatically catalogue the geographic data in a research compendium by parsing computer directories in search of recognised geographic data types, resulting in a list of any potential geographic data sources and their relative locations on a computer drive.
This feature is particularly useful for routinely cataloguing the data sources contained in a research compendium and verifying the completeness of metadata records for the compendium.
Software can also be programmed to automatically extract or calculate geographic metadata, including coordinate reference systems, data types, and spatial extents.
Attribute data can be extracted to facilitate creation and maintenance of data dictionaries, including variable names, attribute data types, feature or observation counts, descriptive statistics for quantitative data, and unique values for categorical data.

If software contains all the features for cataloguing geographic data and much of its geographic and attribute metadata, then it can also be extended to validate individual metadata records or the records for an entire research compendium.
This feature would crosscheck metadata documentation with all automatically derived metadata to report any irregularities or missing information.
In addition, validation should check for compliance with regard to completeness of other required metadata fields which cannot be automatically derived, e.g. authorship, license, and distribution information.

None of this yet ensures compliance with one of the most important functions of metadata: to record provenance.
Researchers working exclusively with Python, R or other computing languages will hopefully have recorded a complete history of data transformations and manipulations in legible code, and this method of provenance documentation requires the metadata to link to permanently accessible code.
Another approach to provenance is to use analytical software that records each step of data transformation as metadata attached to the data itself, which can then be included in the formalised metadata record.
Depending on the software environment, this metadata may even be used as a script of instructions for the software to reproduce the data transformations.

If any geographic metadata software could implement all of the features described above, it would be easier for researchers to 1) document their projects and data according to interoperable and international standards, 2) control the completeness and accuracy of geographic metadata records, and 3) mobilise metadata to support the full research workflow, thereby reducing redundancy and increasing transparency.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Results and Discussion}

The results of our software review are summarised in Table \ref{tab:Metadata_Software}.
We found that no single software program provides all of our desired features for metadata authoring and maintenance, although each of the features exists in at least one of the software programs we reviewed.

The stand-alone metadata editors (mdEditor and Metadata Wizard) are very easy to use, but neither has both the support for international standards and semi-automated authoring features that we were looking for.
Open source desktop GIS software (QGIS, GRASS, and SAGA) have been poor at implementing international metadata standards, negating their usefulness for FAIR data.
SAGA commendably records provenance for each layer, which can be exported as an executable tool chain in XML format.
SAGA also automatically generates geographic and attribute metadata for viewing in the GUI, but does not export the metadata.
QGIS has good support for documenting metadata for projects and layers, but uses its own non-standard format.
Plugins for older versions of QGIS once supported metadata, and our results suggest a need for renewed interest in either updating the QGIS core to conform more precisely to international standards, or adding a metadata project to the public QGIS plugins repository.
The packages for spatial data science in R and Python (geometa and pygeometa) support international standards, but are very difficult to learn and would require additional software code to automate any metadata documentation.
The package for an executable research compendium (o2r-meta) is similarly difficult to learn and does not support international metadata standards.
However, o2r-meta notably has a valuable function to catalogue geographic data layers within the compendium.
Finally, the GeoNetwork and GeoNode content management systems have good support for authoring metadata with international standards, but they have the significant barrier of requiring installation and administration of servers.

In a context in which researchers' time and software tools are already perceived as limitations on reproducible open science, it appears that there is an urgent need for a new open source software tool to facilitate geographic metadata authoring and management in a research compendium.
There are also several existing open source projects from which design ideas and code should be useful.

\section{Conclusions}

Geographic metadata is an essential component of open reproducible science.
Metadata can also contribute to improved transparency and efficiency throughout the full research life cycle and there are currently a number of open source software tools for authoring and maintaining geographic metadata.
However, none of the software currently supports the full range of features desired for supporting metadata-rich research life cycles at every phase.

We conclude that development of a new lightweight and extensible software application for cataloguing and authoring geographic metadata would significantly lower the transaction costs for researchers interested in adopting open science practices throughout the research life cycle, resulting in more FAIR data and reproducible research across the discipline. 
This software tool should include support for the ISO and Dublin Core metadata standards, an intuitive and instructional graphic user interface, functions to automatically catalogue geographic data in a research compendium and automatically populate geographic information and a data dictionary, and validation.
In the future, more advanced development should focus on recording provenance and on using metadata to enrich the full research life cycle by facilitating the creation of research documentation for compendiums, pre-analysis registrations, proposals, data management plans, and human subjects research protocols.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{ACKNOWLEDGEMENTS}\label{ACKNOWLEDGEMENTS}
This research is supported by National Science Foundation project BCS-2049837 and made possible with the hard work of research assistants (Derrick Burt, Drew An-Pham, and Junyi Zhou) and the students in our methods courses.
Responsibility for errors lies with the authors. Corrections and comments on a living version of this paper \citep{foss4g2022} are welcome.

{
	\begin{spacing}{1.17}
		\normalsize
		\bibliography{foss4g_metadata_references} 
	\end{spacing}
}

\end{document}